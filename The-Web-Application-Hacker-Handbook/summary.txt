Rule 1: almost all attacks happen because of unchecked user input

We have to assume all user input is going to be malicious and move accordingly. Sanitize input,
check input at different stages, and having a good system to detect and respond to attacks.

* Request Headers

- The HTTP protocol is one of the most widely used technologies on the web. It is connectionless.

- The referer header simply points to where the request originated from: for example, clicking on
a link leads a website A to go to A.com/link, then the referer for the request would be A.com.

- The hostname is required because multiple websites could be hosted on the same server.

* Response Headers 

- Server header specifies which server software is being used

- Set-cookie sets a cookie (how surprising!!) to be used in later requests 

- Pragma headers instructs browser to not store response in cache

Here are some other types of requests that I didn't have an idea about:

HEAD, basically a GET request without the response body. It's useful to check if the resource exists before
doing a GET.

TRACE, for diagnostic purposes. Checks whether the request message and response body is the same (may be
manipulated when there are proxy servers acting as middlewares in requests)

OPTIONS, for HTTP methods available for resources

PUT, is a dangerous one. If it's enabled, you can upload a script and run it on the server.

This is the format of URLS: protocol://hostname[:port]/[path/]file[?param=value]

- Port is only included if the host's port is different from the one used by the protocol.

* HTTP headers 

1. General

    1.1. Connection - Close the connection or keep-alive for further messages 
    1.2. Content-Encoding - encoding for the message body, such as gzip

2. Requests 

    2.1. Accept encoding - what kind of encodings the client is willing to accept 
    2.2. If-Modified-Since - when the browser last received the resource. If the resource hasn't
                             changed since this time, send the status code 304 (not modified).

3. Response 

    3.1. Cache control
    3.2. ETag - used in conjunction with the If-None-Match request header 
    3.3. Location - redirection, usually with status codes starting with 3
    3.4. WWW-Authenticate - kinds of authentication supported

- Servers issue cookies using the Set-Cookie response header. Then the browser sets the cookie in 
all subsequent requests. Multiple cookies may be set, which will be seperated by ; in the Cookie header.
Eg. Cookie: cookie1;cookie2;cookie3

- The Set-Cookie header can also contain other information such as expires, domain (for which the cookie
is valid), path, secure (so it only applies in HTTPS), and HttpOnly (cannot be accessed on the client side).

* Status codes

1xx — Informational.
2xx — The request was successful.
3xx — The client is redirected to a different resource.
4xx — The request contains an error of some kind.
5xx — The server encountered an error fulfi lling the request


- The main difference between HTTP and HTTPS is that the former is not encrypted, so an attacker can 
see everything is she is positioned on the right side of the network. HTTPS uses SSL (secure socket
layer). 

* When a proxy server is used, there are two differences in how HTTP works

- If it's a HTTP request, the proxy server gets the hostname and the port (which is placed fully by
the browser in the request) which forwards the request to the correct destination server.

- If it's a HTTPS request, the browser can't perform the SSL handshake with the proxy server. Thus,
the browser uses the proxy as pure TCP relay, using which we can perform the SSL handshake. Using a 
proxy server is a good tool to have in your arsenal to intercept requests from your browser to the 
target website.

[Remember that parameters can be sent either via query strings, REST style URLs, cookies, or the body
section of POST requests]

- Applications even go as far as processing the User-Agent to optimize it based on the machine.

* Many apps contain hidden fields within their forms to control what happens after submission. Cookie parameters may also exist. Two types of message bodies are common during form submissions: x-www-form-urlencoded and multipart/formdata. The enctype attribute is required in forms using the latter. It is in these type of requests which you so the long list of parameters in the message body broken up by "------"'s and stuff like that.

- The core API used in Ajax is XMLHttpRequest. 

* Encoding

- URLs are encoded so that problematic characters (like spaces) are taken care of. This is why you see a bunch of random stuff like %20 etc while making HTTP requests. 

%3d — =
%25 — %
%20 — Space (this is akin to the + character)
%0a — New line
%00 — Null byte


- What is unicode? It is an encoding system designed to take care of the world's character set. This works similarly to the URL encoding system in that it has its own symbol for certain characters, preceded by %u.

%u2215 — /
%u00e9 — é

UTF-8 uses each character's byte in hexadecimal preceded by %. 

- You've used HTML encoding before (characters such as &nbsp;).

- Base64 encoding, allows any binary data to be presented as ASCII characters. This one is pretty prominent and can be recognized if there's == signs at the end or by their specific character set. 

- Hex encoding, like base64, always decode these things if they've been sent back from the server

* The best way to explore a website to attack is manually, with a proxy/spider logging requests in the background. After this, follow all links, submit all forms, yada yada.

- 302 found may give you a location header on the response as a redirect, meaning only authenticated users have access to the content. 

- Keep in mind, things like the Server header returned by the Server may be falsified just like how you falsify the User-Agent
header itself. Still, servers can be fingerprinted, using services such as Httprecon. File extensions, default framework error pages,
etc are all things to look for. 

With that being said, here is a roadmap of the rest of the book. These are the things typically involved in writing a 
proper web app, so all of these are fair game.

    Client-side validation — Checks may not be replicated on the server

    Database interaction — SQL injection

    File uploading and downloading — Path traversal vulnerabilities, stored cross-site scripting

    Display of user-supplied data — Cross-site scripting

    Dynamic redirects — Redirection and header injection attacks

    Social networking features — username enumeration, stored cross-site scripting

    Login — Username enumeration, weak passwords, ability to use brute force

    Multistage login — Logic flaws

    Session state — Predictable tokens, insecure handling of tokens

    Access controls — Horizontal and vertical privilege escalation

    User impersonation functions — Privilege escalation

    Use of cleartext communications — Session hijacking, capture of credentials and other sensitive data

    Off-site links — Leakage of query string parameters in the Referer header

    Interfaces to external systems — Shortcuts in the handling of sessions and/or access controls

    Error messages — Information leakage

    E-mail interaction — E-mail and/or command injection

    Native code components or interaction — Buffer overflows

    Use of third-party application components — Known vulnerabilities

    Identifiable web server software — Common configuration weaknesses, known software bugs

Bypassing Client Side controls
------------------------------

- Once again, the core security issues in web apps occur because users can submit arbitrary input. One of the 
most common ways in which data is transferred from client to server is via forms, but the thing is, the data 
might be modified. For instance, if the app uses a third party software, such as a shopping cart, the only way 
for data transmission is through the client. 

* Hidden HTML form elements - Prices in retail websites used to be kept in these! In this day and age, you can
edit that easily using chrome developer tools, but you can also use an intercepting proxy. 

* Cookies - can be intercepted and changed just like above. 

* URL parameters of course

* Strangely, the referer header - this shows where the original source of the request. The assumption is that this is
reliable. Example - if a password reset was requested from a particular resource, it is valid. But we can simply send out
this request from the get go and change the referer header for the request to go through. 

What to do about opaque data? People might encrypt the data being sent in any of these ways.
    1. The app may contain functions to decrypt this for you. 
    2. Copy the value of another item and paste it in this
    3. The server most likely performs validation after decrypting strings like these. Send out malformed variations of this.


If you think you're encountering a base 64 encoded string: if your attempts to decode a Base64 string do not uncover anything
meaningful, try starting from four adjacent offsets into the encoded string. Sometimes you may see gibberish.
Remember that the ASP.NET platform has a ViewState object which keeps track of many user session data. Usually this is protected
by a hash (MAC protection), but if some app has disabled it... party time baby. 

- If you attempt to tamper with HTML forms and you get a Not Modified error code, it is most likely because the browser posseses
a cached version of the resource (can be identified by the If-Modifed-Since or If-None-Match headers). Status codes 304
can be circumvented simply by removing these headers. 

- Browser extensions used are another avenue for attack. The author mentions that there are two main ways to attack browser
extensions: normal request/response interception with a proxy and decompiling the bytecode. For the former, there may be a 
problem of data serialization i.e. you can't understand a thing before deserializing it. To look at bytecode, first you have 
to find the code download URL in the HTML source. Then, depending on which platform's bytecode it is (Java, Flash, etc), decompile 
it, edit the source, and recompile it. How do you actually use your recompiled bytecode? Replace the physical file with yours or
intercepting proxy. 

- Sometimes, as an added security measure, even the bytecode is obfuscated. There are many measures you can take against this.

- On an unrelated note, you can totally execute the bytecode to see what happens too. For example, if the bytecode has been traslated
to be a java program, just add a main function and execute it using the command line! If all this is too much, use the 
debugger, which works at the bytecode level. Even native code can be reverse engineered when websites require native access.

- Make sure to hold critical data on the server. If you don't do this, make sure that your critical data on the client is encrypted
and encrypted well, such that no replay attacks can occur (if you just use base64 or something for a product, then an attacker can copy
paste the encrypted string of a cheaper product). 

* The server side should be aware of the validation schemes used on the client side because if the data somehow still came to the server,
one can be more sure that something malicious is going on for certain. 

Attacking Authentication 
------------------------

Most applications are content with using HTML forms to do authentication. In high risk applications, 
people nowadays use two factor or multi-stage authentication. First and foremost, we have the bad 
password, which can be easily brute forced. Try to register for an account and see the kind of password
rules the application has in place. The best way, I would say, is to limit the number of wrong guesses 
any user can make before locking the account. Holding the "Failed Password Attempts" variable in a cookie 
or session is bad because an attacker can simply intercept and send whatever request they want. 

The author recommends making requests with known usernames and unknown ones in an attempt to view the
different server responses you receive. Verfiy whether the app has an account lockout scheme for 
failed requests. 

Typically, if some data is transmitted over an unencrypted HTTP connection, it can be easily snooped or 
sniffed out. However, even HTTPS connections' data can be compromised if the application hasn't handled 
it well enough. Obviously, put POST request credentials in the request body and not query parameters! 
Do not redirect to a different URL on login! Password change requests need to be authenticated.

Forgot password functionalities contain different challenges (such as mother's maiden name) which is much 
easier than brute forcing a password. The most secure way to handle a password reset is: 

            One reasonably secure means of implementing this is to send a unique,
            unguessable, time-limited recovery URL to the e-mail address that the
            user provided during registration. 

Make sure the email address is the one that the user used while registering, otherwise an attacker could 
just specify his own email address. After each password reset, you must sent an email to the user to 
notify them. 

* The remember me functionality is insecure by design. Facebook's remember me is secure AKA one which 
remembers the username but makes you type in a password the next time you visit. 