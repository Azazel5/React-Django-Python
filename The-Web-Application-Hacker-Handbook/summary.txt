Rule 1: almost all attacks happen because of unchecked user input

We have to assume all user input is going to be malicious and move accordingly. Sanitize input,
check input at different stages, and having a good system to detect and respond to attacks.

* Request Headers

- The HTTP protocol is one of the most widely used technologies on the web. It is connectionless.

- The referer header simply points to where the request originated from: for example, clicking on
a link leads a website A to go to A.com/link, then the referer for the request would be A.com.

- The hostname is required because multiple websites could be hosted on the same server.

* Response Headers 

- Server header specifies which server software is being used

- Set-cookie sets a cookie (how surprising!!) to be used in later requests 

- Pragma headers instructs browser to not store response in cache

Here are some other types of requests that I didn't have an idea about:

HEAD, basically a GET request without the response body. It's useful to check if the resource exists before
doing a GET.

TRACE, for diagnostic purposes. Checks whether the request message and response body is the same (may be
manipulated when there are proxy servers acting as middlewares in requests)

OPTIONS, for HTTP methods available for resources

PUT, is a dangerous one. If it's enabled, you can upload a script and run it on the server.

This is the format of URLS: protocol://hostname[:port]/[path/]file[?param=value]

- Port is only included if the host's port is different from the one used by the protocol.

* HTTP headers 

1. General

    1.1. Connection - Close the connection or keep-alive for further messages 
    1.2. Content-Encoding - encoding for the message body, such as gzip

2. Requests 

    2.1. Accept encoding - what kind of encodings the client is willing to accept 
    2.2. If-Modified-Since - when the browser last received the resource. If the resource hasn't
                             changed since this time, send the status code 304 (not modified).

3. Response 

    3.1. Cache control
    3.2. ETag - used in conjunction with the If-None-Match request header 
    3.3. Location - redirection, usually with status codes starting with 3
    3.4. WWW-Authenticate - kinds of authentication supported

- Servers issue cookies using the Set-Cookie response header. Then the browser sets the cookie in 
all subsequent requests. Multiple cookies may be set, which will be seperated by ; in the Cookie header.
Eg. Cookie: cookie1;cookie2;cookie3

- The Set-Cookie header can also contain other information such as expires, domain (for which the cookie
is valid), path, secure (so it only applies in HTTPS), and HttpOnly (cannot be accessed on the client side).

* Status codes

1xx — Informational.
2xx — The request was successful.
3xx — The client is redirected to a different resource.
4xx — The request contains an error of some kind.
5xx — The server encountered an error fulfi lling the request


- The main difference between HTTP and HTTPS is that the former is not encrypted, so an attacker can 
see everything is she is positioned on the right side of the network. HTTPS uses SSL (secure socket
layer). 

* When a proxy server is used, there are two differences in how HTTP works

- If it's a HTTP request, the proxy server gets the hostname and the port (which is placed fully by
the browser in the request) which forwards the request to the correct destination server.

- If it's a HTTPS request, the browser can't perform the SSL handshake with the proxy server. Thus,
the browser uses the proxy as pure TCP relay, using which we can perform the SSL handshake. Using a 
proxy server is a good tool to have in your arsenal to intercept requests from your browser to the 
target website.

[Remember that parameters can be sent either via query strings, REST style URLs, cookies, or the body
section of POST requests]

- Applications even go as far as processing the User-Agent to optimize it based on the machine.

* Many apps contain hidden fields within their forms to control what happens after submission. Cookie parameters may also exist. Two types of message bodies are common during form submissions: x-www-form-urlencoded and multipart/formdata. The enctype attribute is required in forms using the latter. It is in these type of requests which you so the long list of parameters in the message body broken up by "------"'s and stuff like that.

- The core API used in Ajax is XMLHttpRequest. 

* Encoding

- URLs are encoded so that problematic characters (like spaces) are taken care of. This is why you see a bunch of random stuff like %20 etc while making HTTP requests. 

%3d — =
%25 — %
%20 — Space (this is akin to the + character)
%0a — New line
%00 — Null byte


- What is unicode? It is an encoding system designed to take care of the world's character set. This works similarly to the URL encoding system in that it has its own symbol for certain characters, preceded by %u.

%u2215 — /
%u00e9 — é

UTF-8 uses each character's byte in hexadecimal preceded by %. 

- You've used HTML encoding before (characters such as &nbsp;).

- Base64 encoding, allows any binary data to be presented as ASCII characters. This one is pretty prominent and can be recognized if there's == signs at the end or by their specific character set. 

- Hex encoding, like base64, always decode these things if they've been sent back from the server

* The best way to explore a website to attack is manually, with a proxy/spider logging requests in the background. After this, follow all links, submit all forms, yada yada.

- 302 found may give you a location header on the response as a redirect, meaning only authenticated users have access to the content. 

- Keep in mind, things like the Server header returned by the Server may be falsified just like how you falsify the User-Agent
header itself. Still, servers can be fingerprinted, using services such as Httprecon. File extensions, default framework error pages,
etc are all things to look for. 

With that being said, here is a roadmap of the rest of the book. These are the things typically involved in writing a 
proper web app, so all of these are fair game.

    Client-side validation — Checks may not be replicated on the server

    Database interaction — SQL injection

    File uploading and downloading — Path traversal vulnerabilities, stored cross-site scripting

    Display of user-supplied data — Cross-site scripting

    Dynamic redirects — Redirection and header injection attacks

    Social networking features — username enumeration, stored cross-site scripting

    Login — Username enumeration, weak passwords, ability to use brute force

    Multistage login — Logic flaws

    Session state — Predictable tokens, insecure handling of tokens

    Access controls — Horizontal and vertical privilege escalation

    User impersonation functions — Privilege escalation

    Use of cleartext communications — Session hijacking, capture of credentials and other sensitive data

    Off-site links — Leakage of query string parameters in the Referer header

    Interfaces to external systems — Shortcuts in the handling of sessions and/or access controls

    Error messages — Information leakage

    E-mail interaction — E-mail and/or command injection

    Native code components or interaction — Buffer overflows

    Use of third-party application components — Known vulnerabilities

    Identifiable web server software — Common configuration weaknesses, known software bugs

Bypassing Client Side controls
------------------------------

- Once again, the core security issues in web apps occur because users can submit arbitrary input. One of the 
most common ways in which data is transferred from client to server is via forms, but the thing is, the data 
might be modified. For instance, if the app uses a third party software, such as a shopping cart, the only way 
for data transmission is through the client. 

* Hidden HTML form elements - Prices in retail websites used to be kept in these! In this day and age, you can
edit that easily using chrome developer tools, but you can also use an intercepting proxy. 

* Cookies - can be intercepted and changed just like above. 

* URL parameters of course

* Strangely, the referer header - this shows where the original source of the request. The assumption is that this is
reliable. Example - if a password reset was requested from a particular resource, it is valid. But we can simply send out
this request from the get go and change the referer header for the request to go through. 

What to do about opaque data? People might encrypt the data being sent in any of these ways.
    1. The app may contain functions to decrypt this for you. 
    2. Copy the value of another item and paste it in this
    3. The server most likely performs validation after decrypting strings like these. Send out malformed variations of this.


If you think you're encountering a base 64 encoded string: if your attempts to decode a Base64 string do not uncover anything
meaningful, try starting from four adjacent offsets into the encoded string. Sometimes you may see gibberish.