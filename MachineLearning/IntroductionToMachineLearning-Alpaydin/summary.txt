""" Headings are seperated by --- lines
    Subheadings = *
    Important point = -
"""

Introduction
------------

Machine learning builds off of the idea that in the modern age, people are producers and consumers of data.
Patterns exist in data which can be leverged for profit maximization. At a high level, we use a model with
a set of parameters and the machine's job is to fine tune these parameters (and thus making them more 
accurate) using previous experience or training data. 

* Types of machine learning applications

Basket analyisis: people who buy wines are also more likely to buy wine openers for example. This is 
reminiscent of conditional probability. 

Classification: credit scores are a classification problem i.e. classifying whether a customer is 
high risk or low risk for the financial instituition to lend money to. Discriminant (remember the 
quadratic formula?) seperates different classes. 

- Learning a rule also allows us an opportunity for knowledge extraction. Knowing the discriminant
for low risk customers, we can find the properties of these classes. Using the properties, targeting
these classes becomes easier. 

Regression: Instances where the output is a single number is a regression problem. Regression and classification
are examples of supervised learning. In these problems, there's an input, an output, a function/rule (
regression function or discriminant) and we're trying to minimize the approximation error as much as 
possible. The main difference between supervised and unsupervised learning is that, in the former, the 
supervisor provides the correct value. The latter works simply by finding patterns.

- Clustering is a method of density estimation

Don't think that outliers in the data aren't valuable; in fact, these outliers may be hidden niches which
may be further exploited by the company. Example - diapers. 

Reinforcement learning: What if the output you want is not a single number or a classification? What if 
you want a series of actions (for example, a chess playing agent)? In this case, the important thing is
the policy of actions. 

Supervised learning
-------------------

The data in this kind of machine learning application is labelled which works as the supervisor guiding
the validity of choices that the agent makes. We pick several attributes as our main focuses; for example,
for finding a family car, we pick price x1 and engine power x2, although many others could've been picked.
We have to find a hypothesis class to focus on and then the machine learning algorithm will work on fine
tuning the parameters. 

If classifying is about finding a boolean output for some input, regression is about finding the optimal
function which minimizes empirical error. Sometimes, the data itself isn't enough for the application to 
find a unique solution (also called an ill posed problem). In such cases, we rely on the inductive bias. 
In fact, learning is just not possible without inductive biases because the sky's the limit. When doing
regression, you can choose more and more complex functions, but, although they're more accurate than linear,
they will pose you more headaches down the line. Which biases to go for seems to be the problem and this is 
where model selection comes in. 

- For best generalization AKA how well your agent answers questions not in the training data, we should 
match the complexity of hypothesis class with complexity of function underlying the data. 

- Divide your entire dataset into two parts: training and validation. The hypothesis that is most correct
on the validation set is the correct one. Since the validation set is used to choose the best model, 
splitting the data into a third test set is also a great idea. 